---
title: "Métodos de Regressão"
format: html
lang: "pt-BR"
editor: source
table-of-contents: true
author: "Milena Paz Freitas"
subtitle: "EST066 - 2025.1"
bibliography: "ref.bib"
self-contained: true
csl: "D:/Documentos (D)/UFJF/6-PERIODO/EST. COMPUTACIONAL I/TRABALHO A/Relatorio/abnt.csl"
code-fold: show
code-summary: "<b>Mostrar/esconder código</b>"
nocite: |
  @reginaldo
---

# Introdução

Entre os diferentes métodos de encontrar o melhor ajuste para um conjunto de dados, o mais optado é o método dos mínimos quadrados. Nesse trabalho, o objetivo é explorar esse e outros dois requisitos para otimização numérica do ajuste pela implementação no R, tanto para regressão simples quanto para múltipla, estimação dos erros e performance das funções.

Assim, a organização dos métodos neste trabalho será feita da seguinte forma:

A.
Mínimos Quadrados

B.
Mínimos Desvios Absolutos

C.
Mínima Distância Euclideana

A minimização das funções foi feita por meio da função `stats::optim()`, usando o método Nelder-Mead (default).

# Dados

## 1. Regressão simples

A Tabela 3.1 "Acid Content Data" do livro de Fairley [-@fairley1994] será usada para fazer a implementação dos métodos de regressão simples.

```{r}
#| code-fold: true
ID <- 1:20
Caro<- c(76,70,55,71,55,48,50,66,41,43,82,68,88,58,64,88,89,88,84,88)
Barato<- c(123,109,62,104,57,37,44,100,16,28,138,105,159,75,88,164,169,167,149,167)

dados.1 <- data.frame(ID,Caro,Barato)
rm(list=c("ID","Caro","Barato"))
knitr::kable(dados.1)
```

<br>

#### Modelo Linear

$$
\hat{Y} = \beta_0 + \beta_1X + \epsilon,
$$

onde:

-   $\hat Y$ é a medida de conteúdo de ácido "caro" da amostra química;

-   $X$ é amedida de número de ácido "barato" da amostra química.

-   $\epsilon$ é o erro;

-   $\beta_i$ são os coeficientes de regressão.

## 2. Regressão múltipla

A Tabela 1.1 "Turnip Green Data" [@fairley1994] será usada para fazer a implementação dos métodos de regressão múltipla estudados:

```{r}
#| code-fold: true
ID <- 1:27
B2 <-c(110.4,102.8,101.0,108.4,100.7,100.3,102.0,93.7,98.9,96.6,
99.4,96.2,99.0,88.4,75.3,92.0,82.4,77.1,74.0,65.7,56.8,62.1,61.0,53.2,59.4,58.7,58.0)
Sol <- c(176,155,273,273,256,280,280,184,216,
198,59,80,80,105,180,180,177,230,203,191,191,191,76,213,213,151,205)
Humidade <- c(7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,
2.0,2.0,47.4,47.4,47.4,47.4,47.4,47.4,47.4,47.4,47.4)
Temp.Ar <- c(78,89,89,72,84,87,74,87,88,76,
65,67,62,70,73,65,76,82,76,83,82,69,74,76,69,75,76)

dados.2 <- data.frame(ID,B2,Sol,Humidade,Temp.Ar)
rm(list=c("ID","B2","Sol","Humidade","Temp.Ar"))
knitr::kable(dados.2)
```

<br>

#### Modelos Lineares

$$
\begin{aligned}
&\text{(i)}\quad\hat Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 + \epsilon
\\
&\text{(ii)}\quad\hat Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 + \beta_4X_4 + \epsilon \quad,
\end{aligned}
$$

onde:

-   $\hat Y$ é a concentração de vitamina B2 da planta;

-   $X_1$ é a medida de luz solar para a planta;

-   $X_2$ é a humidade do solo da planta;

-   $X_3$ é a temperatura do ar para a planta;

-   $X_4=X^2_2$.

-   $\epsilon$ é o erro;

-   $\beta_i$ são os coeficientes de regressão.

# A. Mínimos Quadrados

A regressão por mínimos quadrados envolve a minimização de $\sum^n_{i=0}(y_i - \hat{y_i})^2$ por valores de $\beta_i$, $i=0,1,...,n-1$.

Obs.: Quando é assumida a normalidade dos erros $\epsilon_i$, os estimadores por mínimos quadrados são estimadores de máxima verossimilhança dos coeficientes $\beta_i$, $i=0,1,...,n-1$.

Sua implementação no R pode ser feita usando `stats::lm()` ou da forma que segue:

## A.1 Regressão Simples

```{r}
minQuad <- function(b){
  return(sum((dados.1$Caro-b[1]-dados.1$Barato*b[2])^2))
}

(b <-optim(par=c(0,0),minQuad)$par)
coef <- list(simples.A=b)
```

Visualizando o ajuste:

```{r}
#| fig-align: "center"
par(mar=c(4.1,4.1,2.1,1))
plot(Caro ~ Barato,data=dados.1, main="Regressão por Mínimos Quadrados")
abline(a=b[1],b=b[2],lwd=2,col="red")
```

Analisando o modelo:

```{r}
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
resid <- dados.1$Caro - b[1] - b[2]*dados.1$Barato
EQM <- mean(resid^2)
lEQM <- list(simples.A = EQM)
plot(b[1] + b[2]*dados.1$Barato,resid,ylab="Resíduos",xlab="Estimativa de Caro")
abline(h=0,lty=2,col="grey30")
plot(b[1] + b[2]*dados.1$Barato,dados.1$Caro,
     xlab="Estimativa de Caro",ylab="Valor real de Caro")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(EQM,3)),
      side=1,padj=-2,col="blue4")
```

Temos que o ajuste é excelente, com baixo erro quadrático médio.

## A.2 Regressão Múltipla

### Modelo i)

```{r}
matriz <- cbind(1,as.matrix(dados.2[,-(1:2)]))
minQuad <- function(b){
  return(sum((dados.2$B2-matriz%*%b)^2))
}
(b <-optim(par=c(min(dados.2$B2),0,0,0),minQuad)$par)
coef$multi.A1 <- b
```

Analisando o modelo:

```{r}
#| code-fold: true
#| fig-align: "center"
resid <- dados.2$B2-matriz%*%b
EQM <- mean(resid^2)
lEQM$multi1.A <- EQM
#grafico 1
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
plot(matriz%*%b,resid,xlab="Estimativa de B2",ylab="Resíduos",
     col=c("blue","red")[as.numeric(dados.2$Humidade>7)+1])
abline(h=0,lty=2,col="grey30")
#grafico 2
plot(matriz%*%b,dados.2$B2,xlab="Estimativa de B2",ylab="Valor real de B2",
     col=c("blue","red")[as.numeric(dados.2$Humidade>7)+1])
abline(a=0,b=1,lty=2,col="grey30")
legend("topleft",legend=c("Humidade > 7", "Humidade <=7"),col=c("blue","red"),pch=1)
mtext(paste("EQM =",round(mean((dados.2$B2-matriz%*%b)^2),3)),
      side=1,padj=-2,col="blue4")
```

É possível deduzir que o modelo pode não ser o mais adequado para esse conjunto de dados.

### Modelo ii)

```{r}
matriz <- cbind(1,as.matrix(dados.2[,-(1:2)]), dados.2$Humidade^2)
(b <-optim(par=c(100,0,0,0,0),minQuad)$par)
coef$multi1.A <- b
```

Analisando o modelo:

```{r}
#| code-fold: true
#| fig-align: "center"
resid <- dados.2$B2-matriz%*%b
EQM <- mean(resid^2)
lEQM$multi2.A <- EQM
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
plot(matriz%*%b,resid,xlab="Estimativa de B2",ylab="Resíduos")
abline(h=0,lty=2,col="grey30")
plot(matriz%*%b,dados.2$B2,xlab="Estimativa de B2",ylab="Valor real de B2")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(mean((dados.2$B2-matriz%*%b)^2),3)),
      side=1,padj=-2,col="blue4")
```

Observamos melhor ajuste com esse modelo de segundo grau no plot de Estimativa vs Valor Real, e menor erro quadrático médio (EQM). Os erros aparentam estar distribuidos normalmente, o que pode ser testado:

```{r}
ks.test(resid,function(q) pnorm(q, sd=sd(resid)))
```

# B. Mínimos Desvios Absolutos

O objetivo é minimizar a soma do módulo dos desvios: $\sum^n_{i=1}|y_i-\hat y_i|$, que pode ser facilmente implementado no R:

## B.1 Regressão simples

```{r}
minDesv <- function(b){
  return( sum(abs(Y-matriz%*%b)) )
}
Y <- dados.1$Caro
matriz <- cbind(1, dados.1$Barato)
(b<- optim(par=c(1,2), minDesv)$par)
coef$simples.B <- b
```

Visualizando o ajuste:

```{r}
#| fig-align: "center"
par(mar=c(4.1,4.1,2.1,1))
plot(Caro ~ Barato,data=dados.1, main="Regressão por Mínimos Desvios Absolutos")
abline(a=b[1],b=b[2],lwd=2,col="red")
```

Analisando o modelo:

```{r}
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
resid <- dados.1$Caro - b[1] - b[2]*dados.1$Barato
EQM <- mean(resid^2)
lEQM$simples.B <- EQM
plot(b[1] + b[2]*dados.1$Barato,resid,ylab="Resíduos",xlab="Estimativa de Caro")
abline(h=0,lty=2,col="grey30")
plot(b[1] + b[2]*dados.1$Barato,dados.1$Caro,
     xlab="Estimativa de Caro",ylab="Valor real de Caro")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(mean((dados.1$Caro - b[1] - b[2]*dados.1$Barato)^2),3)),
      side=1,padj=-2,col="blue4")
```

O modelo é muito bem ajustado, porém com maior EQM que o método de mínimos quadrados (o que é esperado).

## B.2 Regressão Múltipla

### Modelo i)

```{r}
Y <- dados.2$B2
matriz <- cbind(1,as.matrix(dados.2[,-(1:2)]))
(b <-optim(par=c(min(dados.2$B2),0,0,0),minDesv)$par)
coef$multi1.B <- b
```

Analisando o modelo:

```{r}
#| fig-align: "center"
#| code-fold: true
resid <- dados.2$B2-matriz%*%b
EQM <- mean(resid^2)
lEQM$multi1.B <- EQM
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
plot(matriz%*%b,resid,xlab="Estimativa de B2",ylab="Resíduos",
     col=c("blue","red")[as.numeric(dados.2$Humidade>7)+1])
abline(h=0,lty=2,col="grey30")
plot(matriz%*%b,dados.2$B2,xlab="Estimativa de B2",ylab="Valor real de B2",
     col=c("blue","red")[as.numeric(dados.2$Humidade>7)+1])
abline(a=0,b=1,lty=2,col="grey30")
legend("topleft",legend=c("Humidade > 7", "Humidade <=7"),col=c("blue","red"),pch=1)
mtext(paste("EQM =",round(mean((dados.2$B2-matriz%*%b)^2),3)),
      side=1,padj=-2,col="blue4")
```

Observamos erro quadráditico médio maior que para o método de mínimos quadrados, mas o modelo possui qualidade semelhante.

### Modelo ii)

```{r}
Y<- dados.2$B2
matriz <- cbind(1,as.matrix(dados.2[,-(1:2)]), dados.2$Humidade^2)
(b <-optim(par=c(100,0,0,0,0),minDesv)$par)
coef$multi2.B <- b
```

Analisando o modelo:

```{r}
#| code-fold: true
#| fig-align: "center"
resid <- dados.2$B2-matriz%*%b
EQM <- mean(resid^2)
lEQM$multi2.B <- EQM
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
plot(matriz%*%b,resid,xlab="Estimativa de B2",ylab="Resíduos")
abline(h=0,lty=2,col="grey30")
plot(matriz%*%b,dados.2$B2,xlab="Estimativa de B2",ylab="Valor real de B2")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(mean((dados.2$B2-matriz%*%b)^2),3)),
      side=1,padj=-2,col="blue4")
```

O modelo é decentmente ajustado, mas também possui EQM maior que seu correspondente obtido por mínimos quadrados.

# C. Mínima Distância Euclideana

Deseja-se minimizar a distância euclideana entre os pontos observados e a reta ajustada. Essa quantidade pode ser calculada vetorialmente, da seguinte forma:

Considerando o ponto $v_j=(y_j,x_{1j},...,x_{kj})$, $i= 1,2,...,n$, como uma observação do conjunto de dados, fazemos:

- $\vec v_j=v_j - (\hat \beta_o,0,...,0)$ para deslocar o eixo  ;

- Encontramos um vetor perpendicular à reta usando seus coeficientes (exceto $\beta_0$, por termos deslocado o eixo), expresso de forma:

$$
\vec w = (-1,\beta_1,\beta_2,...,\beta_k)
$$

- Calculamos a projeção de $\vec v_j$ sobre $\vec w$ pela fórmula:

$$
\text{Proj}_\vec{w} \vec{v_j} = \frac{\vec{v_j} \cdot \vec{w}}{\|\vec{w}\|^2} \vec{w}
$$

- Calculamos a norma desse vetor $\text{Proj}_\vec{w} \vec v$, que corresponde à distância do ponto $v_j$ à reta ajustada.

Assim, essa sequência pode ser implementada no R para que possa ser feita a minimização:

## C.1 Regressão Simples

```{r}
matriz <- as.matrix(dados.1[,-1])
distnD <- function(b){
  #deslocamento para a origem
  matriz[,1] <- matriz[,1] - b[1]
  #vetor perpendicular à reta, usando seus coeficientes
  r <- b
  r[1] <- -1
  d<-apply(matriz,1,function(p){
    #projecao do ponto na reta perpendicular
    proj <- as.vector((p%*%r)/(r%*%r))*r
    #norma do vetor(correspondente a distancia)
    return(sqrt(sum(proj^2)))
    #obs: nao e necessário obter essa raiz quadrada, porem
    #   foi importante para convergir com o segundo conjunto de dados
    #   já que estava estourando com valores muito grandes
  })
  return(sum(d))
}
(b<-optim(par=c(min(matriz[,1]),2),distnD)$par)
coef$simples.C <- b
```

Visualizando o ajuste:

```{r}
#| fold-code: true
#| fig-align: "center"
par(mar=c(4.1,4.1,1,1))
plot(Caro ~ Barato,data=dados.1, main="Regressão por Mínima Distância Euclideana")
abline(a=b[1],b=b[2],lwd=2,col="red")
```

Analisando o modelo:

```{r}
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
resid <- dados.1$Caro - b[1] - b[2]*dados.1$Barato
EQM <- mean(resid^2)
lEQM$simples.C <- EQM
plot(b[1] + b[2]*dados.1$Barato,resid,ylab="Resíduos",xlab="Estimativa de Caro")
abline(h=0,lty=2,col="grey30")
plot(b[1] + b[2]*dados.1$Barato,dados.1$Caro,
     xlab="Estimativa de Caro",ylab="Valor real de Caro")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(mean((dados.1$Caro - b[1] - b[2]*dados.1$Barato)^2),3)),
      side=1,padj=-2,col="blue4")
```

Para regressão simples, a performance deste método é comparável aos mínimos desvios.

## C.2 Regressão Múltipla

### Modelo i)

```{r}
#| code-fold: false
matriz <- as.matrix(dados.2[,-1])
(b<-optim(par=c(min(dados.2$B2),0,0,0),distnD)$par)
#nao converge com o mesmo parametro inicial que dos outros métodos...
(b<-optim(par=c(80,0,0,0),distnD)$par)
#assim ele converge
coef$multi1.C <- b
```

Analisando o modelo:

```{r}
#| code-fold: true
#| fig-align: "center"
matriz <- cbind(1,as.matrix(dados.2[,-(1:2)]))
resid <- dados.2$B2-matriz%*%b
EQM <- mean(resid^2)
lEQM$multi1.C <- EQM
#grafico 1
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
plot(matriz%*%b,resid,xlab="Estimativa de B2",ylab="Resíduos")
abline(h=0,lty=2,col="grey30")
#grafico 2
plot(matriz%*%b,dados.2$B2,xlab="Estimativa de B2",ylab="Valor real de B2")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(EQM,3)),side=1,padj=-2,col="blue4")
```

É o maior EQM até então para esse modelo, e a convergência da função é instável para este conjunto de dados.

### Modelo ii)

```{r}
#| code-fold: false
matriz <- as.matrix(cbind(dados.2[,-1], dados.2$Humidade^2))
(b<-optim(par=c(100,0,0,0,0),distnD)$par)
#conseguiu convergir sem problemas usando o mesmo parametro
#inicial que em A e B
coef$multi2.C <- b
```

Analisando o modelo:

```{r}
#| code-fold: true
#| fig-align: "center"
matriz[,1] <- 1
resid <- dados.2$B2-matriz%*%b
EQM <- mean(resid^2)
lEQM$multi2.C <- EQM
par(mfrow=c(1,2),mar=c(4.1,4.1,1,1))
plot(matriz%*%b,resid,xlab="Estimativa de B2",ylab="Resíduos")
abline(h=0,lty=2,col="grey30")
plot(matriz%*%b,dados.2$B2,xlab="Estimativa de B2",ylab="Valor real de B2")
abline(a=0,b=1,lty=2,col="grey30")
mtext(paste("EQM =",round(EQM,3)),side=1,padj=-2,col="blue4")
```

A qualidade do ajuste por minimização da distância depende fortemente dos parâmetros iniciais e do modelo escolhido. O erro quadrático médio, supreendentemente, é menor que o obtido no método por mínimos desvios absolutos.

# Comparações

## Gráficos dos ajustes de regressão simples

```{r}
#| code-fold: true
#| fig-align: "center"
par(mar=c(4.1,4.1,2.1,1))
plot(Caro ~ Barato,data=dados.1, main="Regressão Simples")

abline(a=coef$simples.A[1],b=coef$simples.A[2],col="grey40")
abline(a=coef$simples.B[1],b=coef$simples.B[2],col="darkorange",lty=2)
abline(a=coef$simples.C[1],b=coef$simples.C[2],col="blue",lty=3)
```

```{r}
#| code-fold: true
#| fig-align: "center"
par(mar=c(4.1,4.1,2.1,1))
plot(Caro ~ Barato,data=dados.1, main="Regressão simples (ampliado)",
     xlim=c(10,40),ylim=c(40,50))
abline(a=coef$simples.A[1],b=coef$simples.A[2],col="grey40",lwd=2)
abline(a=coef$simples.B[1],b=coef$simples.B[2],col="darkorange",lty=2,lwd=2)
abline(a=coef$simples.C[1],b=coef$simples.C[2],col="blue",lty=3,lwd=2)
```

## Tabela com os erros quadráticos médios para cada modelo

```{r,echo=FALSE}
#| code-fold: true
letras <- c("A","B","C")
tabela <- cbind(
cbind(lEQM[paste0("simples.",letras)]),
cbind(lEQM[paste0("multi1.",letras)]),
cbind(lEQM[paste0("multi2.",letras)])
)
rownames(tabela)<- letras
knitr::kable(tabela, col.names = c("Método","EQM de reg. simples", "EQM do modelo i)","EQM do modelo ii)"))
```

# Conclusão

Visto que os resultados da regressão por mínimos quadrados foram consistentemente melhores que os outros quanto a facilidade de implementação e qualidade do ajuste, é fácil ver o motivo dela ser a forma mais adotada. Quanto aos ajustes por mínimos desvios absolutos, temos que sua implementação é igualmente simples e consistente, porém rende ajustes com maior erro. O método de mínimas distâncias aparenta ser sensível aos parâmetros iniciais e à qualidade do modelo linear escolhido, mas tem potencial de trazer ajustes mais acurados que o método B, como visto para o modelo ii).